{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25124441",
   "metadata": {},
   "source": [
    "## DreamBank\n",
    "\n",
    "Convert DreamBank's raw HTML files into tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70b705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "import os\n",
    "import re\n",
    "from requests.exceptions import HTTPError\n",
    "import tarfile\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pooch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97697cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/krank-sources/dreambank/releases/download/v1/dreambank.tar.xz' to file 'C:\\Users\\remra\\AppData\\Local\\pooch\\pooch\\Cache\\1078757df23e3b53c13d2bcbb0de123c-dreambank.tar.xz'.\n"
     ]
    }
   ],
   "source": [
    "RAW_URL = \"https://github.com/krank-sources/dreambank/releases/download/v1/dreambank.tar.xz\"\n",
    "RAW_HASH = \"md5:6ab629e9c13251d228db7ec1a93ffeb6\"\n",
    "try:\n",
    "    archive_fname = pooch.retrieve(RAW_URL, RAW_HASH, progressbar=True)\n",
    "except HTTPError as e:\n",
    "    if str(e).startswith(\"404 Client Error: Not Found for url\"):\n",
    "        archive_fname = \"./raw/output/dreambank.tar.xz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da3076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping non-English dataset: german-f.de\n",
      "Dropping non-English dataset: german-m.de\n",
      "Dropping non-English dataset: vonuslar.de\n",
      "Dropping non-English dataset: zurich-f.de\n",
      "Dropping non-English dataset: zurich-m.de\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the datasets available in the archive.\n",
    "datasets = []\n",
    "with tarfile.open(archive_fname, \"r:xz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if member.isdir() and member.name != \".\":\n",
    "            datasets.append(os.path.basename(member.name))\n",
    "\n",
    "# Drop non-english datasets.\n",
    "for ds in datasets[:]:\n",
    "    if \".\" in ds:\n",
    "        datasets.remove(ds)\n",
    "        print(f\"Dropping non-English dataset: {ds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb980fef",
   "metadata": {},
   "source": [
    "## Define functions for HTML extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9b3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_file_content(dataset: str) -> bytes:\n",
    "    \"\"\"Extracts the info.html content for a given dataset from the archive.\"\"\"\n",
    "    with tarfile.open(archive_fname, \"r:xz\") as tar:\n",
    "        fname = f\"./{dataset}/info.html\"\n",
    "        with tar.extractfile(fname) as f:\n",
    "            content = f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "def extract_dream_file_content(dataset: str) -> bytes:\n",
    "    \"\"\"Extracts the dreams.html content for a given dataset from the archive.\"\"\"\n",
    "    with tarfile.open(archive_fname, \"r:xz\") as tar:\n",
    "        fname = f\"./{dataset}/dreams.html\"\n",
    "        with tar.extractfile(fname) as f:\n",
    "            content = f.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d60ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dreams_from_html(dataset: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse DreamBank HTML dreams page for a given dataset into a DataFrame.\"\"\"\n",
    "    content = extract_dream_file_content(dataset)\n",
    "    soup = BeautifulSoup(content, \"html.parser\", from_encoding=\"ISO-8859-1\")\n",
    "    # Find all spans that do not have \"comment\" class labels.\n",
    "    # Comments will already be present in the regular spans/dreams as bracketed content.\n",
    "    data = []\n",
    "    dream_spans = soup.find_all(\"span\", style=False, class_=lambda x: x != \"comment\")\n",
    "    for span in dream_spans:\n",
    "        span_text = span.get_text(separator=\" \", strip=True)\n",
    "        # Extract the dream number from the beginning of string\n",
    "        span_text = span_text.split(\" \", 1)[1]\n",
    "        # Drop the word count from the end of the string\n",
    "        span_text = span_text.rsplit(\"\\n\", 1)[0]\n",
    "        data.append(span_text)\n",
    "        # # Extract the dream number (and potentially date) from beginning of string\n",
    "        # # Sometimes dream number is a string, like 111a (e.g., Alta)\n",
    "        # # Date is sometimes present if provided by dreamer\n",
    "        # # Dream number is always present and represents the number of the dream in the whole sequence\n",
    "        # match_ = re.match(r\"^#(\\S+) ((\\(\\S*\\)) )?\", span_text)\n",
    "        # assert match_ is not None, f\"Did not find dream number match for dataset {dataset}, dream index {i}.\"\n",
    "        # dream_n = match_.group(1)  # The number of dream in the whole sequence\n",
    "        # dream_date = match_.group(3)  # will be None if not found\n",
    "        # # Remove the dream number (and potentially date) from the beginning of string\n",
    "        # dream_and_wc_text = re.sub(r\"^#([0-9]+) ((\\(\\S*\\)) )?\", \"\", span_text)\n",
    "        # # Remove the word count from end of string\n",
    "        # n_wc_matches = len(re.findall(r\"[ \\n]?\\([0-9]+ words\\)$\", dream_and_wc_text))\n",
    "        # assert n_wc_matches == 1, f\"Found {n_wc_matches} WC match for dataset {dataset}, dream {dream_n} (expected 1).\"\n",
    "        # dream_text = re.sub(r\"[ \\n]?\\([0-9]+ words\\)$\", \"\", dream_and_wc_text)\n",
    "        # assert dream_n not in data, f\"Unexpected duplicate dream number: {dream_n} in dataset {dataset}.\"\n",
    "        # data.append(dict(n=dream_n, date=dream_date, dream=dream_text))\n",
    "    # Make sure the correct number of dreams were extracted.\n",
    "    # At the top of each page, DreamBank will say how many dreams are present in the\n",
    "    # total dataset, as well as how many are displayed on the page. These, and the total\n",
    "    # amount of dreams extracted, should all be the same.\n",
    "    # n_dreams_statement = soup.find(\"h4\").find_next().get_text()\n",
    "    # n_dreams_total, n_dreams_displayed = re.findall(r\"[0-9]+\", n_dreams_statement)\n",
    "    # n_dreams_extracted = len(data)\n",
    "    # assert int(n_dreams_total) == int(n_dreams_displayed) == n_dreams_extracted\n",
    "    # dreams = pd.DataFrame(data).replace(dict(date={None: pd.NA})).astype(dict(n=\"string\", date=\"string\", dream=\"string\")).dropna(how=\"all\", axis=1).sort_index(axis=0)\n",
    "    dreams = pd.DataFrame(data, columns=[\"dream\"]).astype(dict(dream=\"string\"))\n",
    "    return dreams\n",
    "\n",
    "\n",
    "def extract_info_from_html(dataset: str) -> dict:\n",
    "    \"\"\"Parse DreamBank HTML info page for a given dataset into a dictionary.\n",
    "\n",
    "    * long_name (str): The dataset title.\n",
    "    * n_dreams (int): The total number of dreams in the dataset.\n",
    "    * timeframe (str): Provided year or timeframe of the dataset.\n",
    "    * sex (str): The provided sex of the dreamer.\n",
    "    * description (str): A long-form description of the dataset.\n",
    "    \"\"\"\n",
    "    content = extract_info_file_content(dataset)\n",
    "    soup = BeautifulSoup(content, \"html.parser\", from_encoding=\"ISO-8859-1\")\n",
    "    body = soup.find(\"body\")\n",
    "    long_name = body.find(string=\"Dream series:\").next.get_text(strip=True)\n",
    "    n_dreams = body.find(string=\"Number of dreams:\").next.get_text(strip=True)\n",
    "    timeframe = body.find(string=\"Year:\").next.get_text(strip=True)\n",
    "    sex = body.find(string=\"Sex of the dreamer(s):\").next.get_text(strip=True)\n",
    "    match_ = re.match(\n",
    "        rf\".*Sex of the dreamer\\(s\\): {sex}\\n\\n\\n?(.*?)\\s+(For the further analyses, click here.\\n)?\\[Back to search form\\]\\s+$\",\n",
    "        body.get_text(),\n",
    "        flags=re.DOTALL\n",
    "    )\n",
    "    assert match_ is not None, f\"Error parsing info description for dataset {dataset}.\"\n",
    "    description = match_.group(1)\n",
    "    info = {\n",
    "        \"long_name\": long_name,\n",
    "        \"n_dreams\": n_dreams,\n",
    "        \"timeframe\": timeframe,\n",
    "        \"sex\": sex,\n",
    "        \"description\": description,\n",
    "    }\n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17546dca",
   "metadata": {},
   "source": [
    "## Process each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5622dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset west_coast_teens: 100%|████████████████| 89/89 [03:10<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = {}\n",
    "for dataset in (pbar := tqdm.tqdm(datasets, ncols=90)):\n",
    "    pbar.set_description(f\"Processing dataset {dataset}\")\n",
    "    extracted_data[dataset] = {\n",
    "        \"info\": extract_info_from_html(dataset),\n",
    "        \"dreams\": extract_dreams_from_html(dataset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54fb730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all info dicts into a single DataFrame\n",
    "all_info = pd.DataFrame.from_dict(\n",
    "    {ds: extracted_data[ds][\"info\"] for ds in extracted_data},\n",
    "    orient=\"index\"\n",
    ").rename_axis(\"dataset\").reset_index(drop=False)\n",
    "\n",
    "# Combine all dreams DataFrames into a single DataFrame with a multi-index\n",
    "all_dreams = pd.concat(\n",
    "    {\n",
    "        ds: extracted_data[ds][\"dreams\"]\n",
    "        for ds in extracted_data\n",
    "    },\n",
    "    names=[\"dataset\"]\n",
    ").droplevel(1).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0d4f2",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b42aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"./output\"\n",
    "DREAMS_FNAME = \"dreams.csv\"\n",
    "INFO_FNAME = \"info.csv\"\n",
    "dreams_outpath = f\"{OUTDIR}/{DREAMS_FNAME}\"\n",
    "info_outpath = f\"{OUTDIR}/{INFO_FNAME}\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "TO_CSV_KWARGS = {\n",
    "    \"index\": False,\n",
    "    \"sep\": \",\",\n",
    "    \"mode\": \"x\",  # Switch to `w` to overwrite existing file\n",
    "    \"encoding\": \"utf-8-sig\",  # Include sig/BOM for better compatibility with Excel\n",
    "    \"lineterminator\": \"\\n\",\n",
    "    \"quoting\": 2,  # 2 = csv.QUOTE_NONNUMERIC\n",
    "    \"quotechar\": '\"',\n",
    "    \"doublequote\": True,\n",
    "}\n",
    "all_dreams.to_csv(dreams_outpath, **TO_CSV_KWARGS)\n",
    "all_info.to_csv(info_outpath, **TO_CSV_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ea3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: dreams.csv\n",
      "size: 33.72761 MB\n",
      "md5: 79c40db24e7343cbab2ba88040fbd6da\n",
      "sha256: bef1b3121d402e59eb2480176048c127d13e46a3529b850ad407cf3b1d3674aa\n",
      "timestamp: 2025-12-29T01:47:19+00:00\n",
      "\n",
      "file: info.csv\n",
      "size: 0.059037 MB\n",
      "md5: e169da104778fc00536f5f55b68ddabf\n",
      "sha256: 30a7fc3ead9a3fc02fa9dd0c8898f1aadb16e40250ee23212ac94132a663e4f5\n",
      "timestamp: 2025-12-29T01:47:19+00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fn in [dreams_outpath, info_outpath]:\n",
    "    print(f\"file: {os.path.basename(fn)}\")\n",
    "    print(f\"size: {os.path.getsize(fn) / 1e6} MB\")\n",
    "    print(f\"md5: {pooch.file_hash(fn, alg='md5')}\")\n",
    "    print(f\"sha256: {pooch.file_hash(fn, alg='sha256')}\")\n",
    "    print(f\"timestamp: {datetime.fromtimestamp(os.path.getmtime(fn), tz=timezone.utc).isoformat(timespec='seconds')}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
